{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, you will use data sourced from the Open Database of Addresses (ODA) provided courtesy of Statistics Canada. You can find the link to the database here: https://www.statcan.gc.ca/en/lode/databases/oda. \n",
    "\n",
    "This data is provided under the terms of the [Open Government License - Canada](https://open.canada.ca/en/open-government-licence-canada). \n",
    "\n",
    "You can find the data as a zipfile in D2L with the assignment, and you should unpack this and run it in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "First, explore your data and the conversion task that you will be working with. In the cell below:\n",
    "\n",
    "Compare the conversion of the files to parquet using different compression algorithms. What is the difference between using no compression, snappy, and gzip? Comment on processing times and approximately how much compression you observe has been achieved with this data.\n",
    "\n",
    "Note: You may have some issues running this with the brotli compression algorithm.\n",
    "\n",
    "Based on any sources you can find online (please include your references cite them approriately), how different would using brotli be? What would you expect in terms of processing time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED\n",
    "import pandas as pd\n",
    "import random\n",
    "import time \n",
    "from pathlib import Path\n",
    "\n",
    "def convert_csv_to_parquet(src, dst, method):\n",
    "    # print(f\"Converting {src} to {dst}\")\n",
    "    df = pd.read_csv(src, low_memory=False)\n",
    "    df.to_parquet(dst, compression=method)\n",
    "    \n",
    "file_list = list(Path('address_data').glob('address_*.csv'))\n",
    "random.shuffle(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: 119.2666 seconds\n",
      "None: 55.6176 seconds\n",
      "snappy: 54.5760 seconds\n",
      "brotli: 135.7738 seconds\n"
     ]
    }
   ],
   "source": [
    "# MODIFIED\n",
    "methods = ['gzip', 'None', 'snappy', 'brotli']\n",
    "def file_conversion(file_list, methods):\n",
    "    for method in methods:\n",
    "        start_time = time.time()\n",
    "        for ind, src in enumerate(file_list):\n",
    "            dest = str(src.with_suffix('.parquet'))\n",
    "            convert_csv_to_parquet(src, dest, method)\n",
    "        print(f\"{method}: {time.time()-start_time:.4f} seconds\")\n",
    "file_conversion(file_list, methods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Order of compression algorithm speeds:\n",
    "\n",
    "brotli: 135sec <br>\n",
    "gzip: 119sec <br>\n",
    "none: 55sec <br>\n",
    "snappy: 54sec <br>\n",
    "\n",
    "After some research online regardign these algorithms, this is why I believe they behaved in the way they did:\n",
    "\n",
    "Sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Parallelize the code above using either processes or threads.\n",
    "\n",
    "Use comments reading `# MODIFIED` to indicate any code cells you have changed and `# NEW` to indicate any code cells you have added.\n",
    "\n",
    "With respect to the improvement in runtimes, do you think this is reasonably characteristic? What happens if you use a pool of threads or processes? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: 62.74 seconds\n",
      "None: 47.84 seconds\n",
      "snappy: 56.58 seconds\n",
      "brotli: 88.44 seconds\n"
     ]
    }
   ],
   "source": [
    "# NEW \n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "def convert_csv_to_parquet(src, dst, method):\n",
    "    df = pd.read_csv(src, low_memory=False)\n",
    "    return df.to_parquet(dst, compression=method)\n",
    "\n",
    "def thread_pool_func():\n",
    "    for method in ['gzip', 'None', 'snappy', 'brotli']:\n",
    "        start_time = time.time()\n",
    "        with Pool(multiprocessing.cpu_count()) as pool:\n",
    "            pool.starmap(convert_csv_to_parquet, [(f, str(f.with_suffix('.parquet')), method) for f in file_list])\n",
    "        print(f\"{method}: {time.time()-start_time:.4f} seconds\")\n",
    "\n",
    "thread_pool_func()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Using thread pools for multiprocessing, the Brotli and gzip compression algorithms have significantly reduced. However the snappy algorthim was about the same, if not a little slower. Using no algorithm was a little faster using thread pools.\n",
    "\n",
    "Bbotli: 88sec <br>\n",
    "gzip: 63sec <br>\n",
    "snappy: 56sec <br>\n",
    "none: 48sec <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Share one way in which you could improve the running of this test. You may consider (but are not limited to) your runtime environment, the test data provided, or the manner in which this test was run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
